{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1c6d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Data-GP1_with_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a725f97",
   "metadata": {},
   "source": [
    "1) Define the objective + guard against leakage\n",
    "\n",
    "Decide what you can know at prediction time. If you’re quoting a price at purchase time, drop any features that peek into the future (e.g., COVID around departure if not known yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a75453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features: ['lead_time_days', 'Culmulative_sales', 'route_sales_rank', 'sales_diff_1', 'price_to_route_month_mean', 'route_month_mean_price', 'isReturn', 'isOneway', 'isNormCabin', 'is_weekend_dept', 'is_weekend_purchase', 'is_holiday_dept', 'is_holiday_purchase', 'return_x_norm', 'oneway_x_norm', 'return_x_weekend', 'oneway_x_weekend', 'dept_weekday', 'purchase_weekday', 'dept_season', 'Train_Number_All', 'Customer_Cat']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Target (log helps linear models + stabilizes variance)\n",
    "TARGET = \"mean_net_ticket_price\"\n",
    "df = df.copy()\n",
    "df[\"y_log\"] = np.log1p(df[TARGET])\n",
    "\n",
    "num_feats = [\n",
    "    \"lead_time_days\",\n",
    "    \"Culmulative_sales\",\"route_sales_rank\",\"sales_diff_1\",\n",
    "    \"price_to_route_month_mean\",\"route_month_mean_price\",\n",
    "    \"covid_cases_at_purchase\",\"stringency_at_purchase\",\n",
    "]\n",
    "\n",
    "bool_feats = [\n",
    "    \"isReturn\",\"isOneway\",\"isNormCabin\",\n",
    "    \"is_weekend_dept\",\"is_weekend_purchase\",\n",
    "    \"is_holiday_dept\",\"is_holiday_purchase\",\n",
    "    \"is_sg_holiday_dept\",\"is_us_holiday_dept\",\"is_cn_holiday_dept\",\"is_fr_holiday_dept\",\"is_in_holiday_dept\",\"is_ru_holiday_dept\",\n",
    "    \"is_sg_holiday_purchase\",\"is_us_holiday_purchase\",\"is_cn_holiday_purchase\",\"is_fr_holiday_purchase\",\"is_in_holiday_purchase\",\"is_ru_holiday_purchase\",\n",
    "    \"return_x_norm\",\"oneway_x_norm\",\"return_x_weekend\",\"oneway_x_weekend\",\n",
    "]\n",
    "\n",
    "cat_feats = [\n",
    "    \"dept_weekday\",\"purchase_weekday\",\"dept_season\",\n",
    "    \"Train_Number_All\",\"Customer_Cat\"\n",
    "]\n",
    "\n",
    "# Keep only columns that exist\n",
    "num_feats  = [c for c in num_feats  if c in df.columns]\n",
    "bool_feats = [c for c in bool_feats if c in df.columns]\n",
    "cat_feats  = [c for c in cat_feats  if c in df.columns]\n",
    "\n",
    "X_cols = num_feats + bool_feats + cat_feats\n",
    "print(\"Using features:\", X_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c002b6",
   "metadata": {},
   "source": [
    "Time-aware train/test split\n",
    "\n",
    "Don’t shuffle randomly when there’s time involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b267ee28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-01 00:00:00 → 2019-04-22 00:00:00 | TRAIN\n",
      "2019-04-22 00:00:00 → 2019-06-30 00:00:00 | TEST\n"
     ]
    }
   ],
   "source": [
    "# Ensure dates are datetime\n",
    "for c in [\"Purchase_Date\",\"Dept_Date\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "\n",
    "df_sorted = df.sort_values(\"Purchase_Date\").reset_index(drop=True)\n",
    "\n",
    "cut = int(len(df_sorted) * 0.8)  # 80% train, 20% test (time ordered)\n",
    "train = df_sorted.iloc[:cut].copy()\n",
    "test  = df_sorted.iloc[cut:].copy()\n",
    "\n",
    "X_train, y_train = train[X_cols], train[\"y_log\"]\n",
    "X_test,  y_test  = test[X_cols],  test[\"y_log\"]\n",
    "\n",
    "print(train[\"Purchase_Date\"].min(), \"→\", train[\"Purchase_Date\"].max(), \"| TRAIN\")\n",
    "print(test[\"Purchase_Date\"].min(),  \"→\", test[\"Purchase_Date\"].max(),  \"| TEST\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94138be",
   "metadata": {},
   "source": [
    "Preprocess + LASSO (with CV)\n",
    "\n",
    "Scale numeric/boolean, one-hot categoricals, and run LassoCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1aa5ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha (LASSO): 0.0008036432311789218\n",
      "Non-zero coefs: 28\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "numeric = num_feats + bool_feats   # scale both numeric + 0/1 flags\n",
    "categorical = cat_feats\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(with_mean=True, with_std=True), numeric),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "alphas = np.logspace(-4, 1.5, 80)  # search from 1e-4 to ~31\n",
    "lasso = LassoCV(alphas=alphas, cv=5, random_state=42, n_jobs=-1, max_iter=20000)\n",
    "\n",
    "pipe_lasso = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"model\", lasso)\n",
    "])\n",
    "\n",
    "pipe_lasso.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best alpha (LASSO):\", pipe_lasso.named_steps[\"model\"].alpha_)\n",
    "print(\"Non-zero coefs:\", np.sum(pipe_lasso.named_steps[\"model\"].coef_ != 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86173f9",
   "metadata": {},
   "source": [
    "Evaluate (log space + back-transform)\n",
    "\n",
    "Report MAE/RMSE/ MAP E on the original price scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7d3f991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO {'R2_tr_log': 0.9433488946681736, 'R2_te_log': 0.9355304007781823, 'MAE_tr': 93187001.67857896, 'RMSE_tr': 38167660650.91753, 'MAPE_tr_%': 1186234.5385857795, 'R2_tr_orig': -6.555408697723465e+16, 'MAE_te': 43.03533610509039, 'RMSE_te': 2591.346246336126, 'MAPE_te_%': 11.383290697231866, 'R2_te_orig': -361.46933405071564, 'MAE_te_smear': 43.234643255332195, 'RMSE_te_smear': 2613.996820373126, 'MAPE_te_smear_%': 11.446320698789643, 'R2_te_orig_smear': -367.8336092234766, 'SmearingFactor': 1.0087088013709464}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate(pipe, X_tr, y_tr, X_te, y_te, label=\"Model\"):\n",
    "    # predictions in log1p space\n",
    "    pred_tr = pipe.predict(X_tr)\n",
    "    pred_te = pipe.predict(X_te)\n",
    "\n",
    "    # true values (original scale)\n",
    "    y_tr_true = np.expm1(y_tr)\n",
    "    y_te_true = np.expm1(y_te)\n",
    "\n",
    "    # naive back-transform\n",
    "    y_tr_hat_naive = np.expm1(pred_tr)\n",
    "    y_te_hat_naive = np.expm1(pred_te)\n",
    "\n",
    "    # Duan smearing correction for log1p models\n",
    "    resid_tr = y_tr - pred_tr                       # residuals in log space\n",
    "    smear = float(np.mean(np.exp(resid_tr)))        # E[exp(e)]\n",
    "    y_tr_hat_smear = smear * np.exp(pred_tr) - 1.0\n",
    "    y_te_hat_smear = smear * np.exp(pred_te) - 1.0\n",
    "\n",
    "    # clip tiny negatives\n",
    "    y_tr_hat_naive = np.clip(y_tr_hat_naive, 0, None)\n",
    "    y_te_hat_naive = np.clip(y_te_hat_naive, 0, None)\n",
    "    y_tr_hat_smear = np.clip(y_tr_hat_smear, 0, None)\n",
    "    y_te_hat_smear = np.clip(y_te_hat_smear, 0, None)\n",
    "\n",
    "    def rmse(y_true, y_pred):\n",
    "        return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "    def mape(y_true, y_pred):\n",
    "        return float(np.mean(np.abs((y_true - y_pred) / np.clip(y_true, 1e-8, None))) * 100)\n",
    "\n",
    "    metrics = {\n",
    "        # log-space fit (your original intent)\n",
    "        \"R2_tr_log\": r2_score(y_tr, pred_tr),\n",
    "        \"R2_te_log\": r2_score(y_te, pred_te),\n",
    "\n",
    "        # original-scale (naive back-transform)\n",
    "        \"MAE_tr\": mean_absolute_error(y_tr_true, y_tr_hat_naive),\n",
    "        \"RMSE_tr\": rmse(y_tr_true, y_tr_hat_naive),\n",
    "        \"MAPE_tr_%\": mape(y_tr_true, y_tr_hat_naive),\n",
    "        \"R2_tr_orig\": r2_score(y_tr_true, y_tr_hat_naive),\n",
    "\n",
    "        \"MAE_te\": mean_absolute_error(y_te_true, y_te_hat_naive),\n",
    "        \"RMSE_te\": rmse(y_te_true, y_te_hat_naive),\n",
    "        \"MAPE_te_%\": mape(y_te_true, y_te_hat_naive),\n",
    "        \"R2_te_orig\": r2_score(y_te_true, y_te_hat_naive),\n",
    "\n",
    "        # smearing-corrected (often better calibrated)\n",
    "        \"MAE_te_smear\": mean_absolute_error(y_te_true, y_te_hat_smear),\n",
    "        \"RMSE_te_smear\": rmse(y_te_true, y_te_hat_smear),\n",
    "        \"MAPE_te_smear_%\": mape(y_te_true, y_te_hat_smear),\n",
    "        \"R2_te_orig_smear\": r2_score(y_te_true, y_te_hat_smear),\n",
    "\n",
    "        \"SmearingFactor\": smear,\n",
    "    }\n",
    "\n",
    "    print(label, metrics)\n",
    "    return metrics\n",
    "\n",
    "# usage\n",
    "m_lasso = evaluate(pipe_lasso, X_train, y_train, X_test, y_test, \"LASSO\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22611717",
   "metadata": {},
   "source": [
    "Which features did LASSO keep?\n",
    "\n",
    "Get feature names after preprocessing and list non-zero coefficients (standardized)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e2d2bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO kept 28 / 52 features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>price_to_route_month_mean</td>\n",
       "      <td>0.459848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>route_month_mean_price</td>\n",
       "      <td>0.207496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Train_Number_All_C</td>\n",
       "      <td>0.044209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lead_time_days</td>\n",
       "      <td>-0.043307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>isNormCabin</td>\n",
       "      <td>-0.040761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dept_season_Winter</td>\n",
       "      <td>0.032968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Customer_Cat_A</td>\n",
       "      <td>0.027920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Culmulative_sales</td>\n",
       "      <td>-0.023946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>isOneway</td>\n",
       "      <td>-0.016651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>route_sales_rank</td>\n",
       "      <td>-0.015063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dept_weekday_Friday</td>\n",
       "      <td>0.013914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>oneway_x_norm</td>\n",
       "      <td>0.011994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Train_Number_All_E</td>\n",
       "      <td>0.011852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Train_Number_All_D</td>\n",
       "      <td>-0.010863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>is_weekend_dept</td>\n",
       "      <td>0.010786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Train_Number_All_B</td>\n",
       "      <td>0.008896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Train_Number_All_K</td>\n",
       "      <td>-0.007213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Train_Number_All_F</td>\n",
       "      <td>0.005834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Train_Number_All_J</td>\n",
       "      <td>-0.004555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sales_diff_1</td>\n",
       "      <td>-0.004139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>return_x_weekend</td>\n",
       "      <td>0.003884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>is_weekend_purchase</td>\n",
       "      <td>-0.003400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>isReturn</td>\n",
       "      <td>0.002631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>is_holiday_dept</td>\n",
       "      <td>0.002008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Train_Number_All_A</td>\n",
       "      <td>-0.001012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dept_weekday_Tuesday</td>\n",
       "      <td>-0.000779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dept_weekday_Sunday</td>\n",
       "      <td>0.000310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dept_season_Spring</td>\n",
       "      <td>-0.000168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature  coef_std\n",
       "4   price_to_route_month_mean  0.459848\n",
       "5      route_month_mean_price  0.207496\n",
       "21         Train_Number_All_C  0.044209\n",
       "0              lead_time_days -0.043307\n",
       "8                 isNormCabin -0.040761\n",
       "18         dept_season_Winter  0.032968\n",
       "27             Customer_Cat_A  0.027920\n",
       "1           Culmulative_sales -0.023946\n",
       "7                    isOneway -0.016651\n",
       "2            route_sales_rank -0.015063\n",
       "14        dept_weekday_Friday  0.013914\n",
       "12              oneway_x_norm  0.011994\n",
       "23         Train_Number_All_E  0.011852\n",
       "22         Train_Number_All_D -0.010863\n",
       "9             is_weekend_dept  0.010786\n",
       "20         Train_Number_All_B  0.008896\n",
       "26         Train_Number_All_K -0.007213\n",
       "24         Train_Number_All_F  0.005834\n",
       "25         Train_Number_All_J -0.004555\n",
       "3                sales_diff_1 -0.004139\n",
       "13           return_x_weekend  0.003884\n",
       "10        is_weekend_purchase -0.003400\n",
       "6                    isReturn  0.002631\n",
       "11            is_holiday_dept  0.002008\n",
       "19         Train_Number_All_A -0.001012\n",
       "16       dept_weekday_Tuesday -0.000779\n",
       "15        dept_weekday_Sunday  0.000310\n",
       "17         dept_season_Spring -0.000168"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get transformed feature names\n",
    "cat_names = pipe_lasso.named_steps[\"pre\"].named_transformers_[\"cat\"].get_feature_names_out(categorical) if categorical else np.array([])\n",
    "feat_names = np.concatenate([numeric, cat_names])\n",
    "\n",
    "coefs = pipe_lasso.named_steps[\"model\"].coef_\n",
    "mask = coefs != 0\n",
    "selected = pd.DataFrame({\n",
    "    \"feature\": feat_names[mask],\n",
    "    \"coef_std\": coefs[mask]\n",
    "}).sort_values(\"coef_std\", key=lambda s: np.abs(s), ascending=False)\n",
    "\n",
    "print(f\"LASSO kept {mask.sum()} / {len(feat_names)} features\")\n",
    "selected.head(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dc0b5f",
   "metadata": {},
   "source": [
    "Human-readable formula\n",
    "\n",
    "Coefficients above are for standardized inputs. To get a simple linear formula in original units, refit a plain LinearRegression on only the selected columns using the same one-hot, but without scaling numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbabb120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model (log-price) with selected features\n",
      "Intercept: 3.7438492233079774\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>price_to_route_month_mean</td>\n",
       "      <td>0.796879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Train_Number_All_C</td>\n",
       "      <td>0.052980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>isNormCabin</td>\n",
       "      <td>-0.041483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>isNormCabin</td>\n",
       "      <td>-0.041483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>dept_season_Winter</td>\n",
       "      <td>0.037961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Train_Number_All_K</td>\n",
       "      <td>-0.037427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>oneway_x_norm</td>\n",
       "      <td>0.031556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>oneway_x_norm</td>\n",
       "      <td>0.031556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Customer_Cat_A</td>\n",
       "      <td>0.031231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>isOneway</td>\n",
       "      <td>-0.029947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>isOneway</td>\n",
       "      <td>-0.029947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Train_Number_All_D</td>\n",
       "      <td>-0.026379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Train_Number_All_E</td>\n",
       "      <td>0.024229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dept_weekday_Friday</td>\n",
       "      <td>0.020749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Train_Number_All_B</td>\n",
       "      <td>0.018445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Train_Number_All_F</td>\n",
       "      <td>0.017674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Train_Number_All_J</td>\n",
       "      <td>-0.017475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Train_Number_All_A</td>\n",
       "      <td>-0.015778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>is_weekend_dept</td>\n",
       "      <td>0.010969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>is_weekend_dept</td>\n",
       "      <td>0.010969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dept_weekday_Sunday</td>\n",
       "      <td>0.008714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>is_holiday_dept</td>\n",
       "      <td>0.008504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>is_holiday_dept</td>\n",
       "      <td>0.008504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>return_x_weekend</td>\n",
       "      <td>0.005974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>return_x_weekend</td>\n",
       "      <td>0.005974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dept_weekday_Tuesday</td>\n",
       "      <td>-0.005776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>is_weekend_purchase</td>\n",
       "      <td>-0.004811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>is_weekend_purchase</td>\n",
       "      <td>-0.004811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>isReturn</td>\n",
       "      <td>0.004426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>isReturn</td>\n",
       "      <td>0.004426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature      coef\n",
       "4   price_to_route_month_mean  0.796879\n",
       "29         Train_Number_All_C  0.052980\n",
       "8                 isNormCabin -0.041483\n",
       "16                isNormCabin -0.041483\n",
       "26         dept_season_Winter  0.037961\n",
       "34         Train_Number_All_K -0.037427\n",
       "20              oneway_x_norm  0.031556\n",
       "12              oneway_x_norm  0.031556\n",
       "35             Customer_Cat_A  0.031231\n",
       "15                   isOneway -0.029947\n",
       "7                    isOneway -0.029947\n",
       "30         Train_Number_All_D -0.026379\n",
       "31         Train_Number_All_E  0.024229\n",
       "22        dept_weekday_Friday  0.020749\n",
       "28         Train_Number_All_B  0.018445\n",
       "32         Train_Number_All_F  0.017674\n",
       "33         Train_Number_All_J -0.017475\n",
       "27         Train_Number_All_A -0.015778\n",
       "17            is_weekend_dept  0.010969\n",
       "9             is_weekend_dept  0.010969\n",
       "23        dept_weekday_Sunday  0.008714\n",
       "11            is_holiday_dept  0.008504\n",
       "19            is_holiday_dept  0.008504\n",
       "21           return_x_weekend  0.005974\n",
       "13           return_x_weekend  0.005974\n",
       "24       dept_weekday_Tuesday -0.005776\n",
       "10        is_weekend_purchase -0.004811\n",
       "18        is_weekend_purchase -0.004811\n",
       "6                    isReturn  0.004426\n",
       "14                   isReturn  0.004426"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a 'no-scale' preprocessor (one-hot only), then restrict to selected columns\n",
    "pre_noscale = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", \"passthrough\", numeric + bool_feats),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# Fit on TRAIN to get transformed matrix & names\n",
    "Xtr_n = pre_noscale.fit_transform(X_train)\n",
    "cat_names_n = pre_noscale.named_transformers_[\"cat\"].get_feature_names_out(categorical) if categorical else np.array([])\n",
    "feat_names_n = np.concatenate([numeric + bool_feats, cat_names_n])\n",
    "\n",
    "# Keep only the features LASSO selected (intersection by name)\n",
    "keep_set = set(selected[\"feature\"])\n",
    "keep_idx = [i for i, n in enumerate(feat_names_n) if n in keep_set]\n",
    "\n",
    "Xtr_sel = Xtr_n[:, keep_idx]\n",
    "Xte_sel = pre_noscale.transform(X_test)[:, keep_idx]\n",
    "feat_sel_names = [feat_names_n[i] for i in keep_idx]\n",
    "\n",
    "ols = LinearRegression()\n",
    "ols.fit(Xtr_sel, y_train)\n",
    "\n",
    "coef = pd.DataFrame({\"feature\": feat_sel_names, \"coef\": ols.coef_}).sort_values(\"coef\", key=lambda s: np.abs(s), ascending=False)\n",
    "intercept = ols.intercept_\n",
    "\n",
    "print(\"Linear model (log-price) with selected features\")\n",
    "print(\"Intercept:\", intercept)\n",
    "coef.head(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252cc0a0",
   "metadata": {},
   "source": [
    "Your formula in log space is:\n",
    "log(1 + price) = Intercept + Σ coef_i * feature_i\n",
    "To predict price: price_hat = exp(Intercept + Σ coef_i * feature_i) - 1.\n",
    "\n",
    "(If you want statistical p-values / confidence intervals, swap LinearRegression with statsmodels.api.OLS on Xtr_sel and y_train.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e417ec",
   "metadata": {},
   "source": [
    "Which ones to keep? (beyond LASSO)\n",
    "\n",
    "Permutation importance (model-agnostic): keeps features that truly affect predictions on the holdout.\n",
    "\n",
    "Stability selection (bootstrap): keeps features repeatedly chosen across resamples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ab3adca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minspection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m permutation_importance\n\u001b[32m      3\u001b[39m perm = permutation_importance(pipe_lasso, X_test, y_test, n_repeats=\u001b[32m40\u001b[39m, random_state=\u001b[32m42\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m perm_imp = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfeature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimport_mean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimportances_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimport_std\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimportances_std\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m.sort_values(\u001b[33m\"\u001b[39m\u001b[33mimport_mean\u001b[39m\u001b[33m\"\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     10\u001b[39m perm_imp.head(\u001b[32m20\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/train_sales_predictor/venv/lib/python3.13/site-packages/pandas/core/frame.py:778\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    772\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    773\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    774\u001b[39m     )\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    777\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     mgr = \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/train_sales_predictor/venv/lib/python3.13/site-packages/pandas/core/internals/construction.py:503\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    500\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    501\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/train_sales_predictor/venv/lib/python3.13/site-packages/pandas/core/internals/construction.py:114\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         index = \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    116\u001b[39m         index = ensure_index(index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/train_sales_predictor/venv/lib/python3.13/site-packages/pandas/core/internals/construction.py:677\u001b[39m, in \u001b[36m_extract_index\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    675\u001b[39m lengths = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[32m    676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAll arrays must be of the same length\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[32m    680\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    681\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    682\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "perm = permutation_importance(pipe_lasso, X_test, y_test, n_repeats=40, random_state=42, n_jobs=-1)\n",
    "perm_imp = pd.DataFrame({\n",
    "    \"feature\": feat_names,\n",
    "    \"import_mean\": perm.importances_mean,\n",
    "    \"import_std\": perm.importances_std\n",
    "}).sort_values(\"import_mean\", ascending=False)\n",
    "\n",
    "perm_imp.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ab577f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
