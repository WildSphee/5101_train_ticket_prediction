{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1c6d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Data-GP1_with_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a725f97",
   "metadata": {},
   "source": [
    "1) Define the objective + guard against leakage\n",
    "\n",
    "Decide what you can know at prediction time. If you’re quoting a price at purchase time, drop any features that peek into the future (e.g., COVID around departure if not known yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90a75453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features: ['lead_time_days', 'route_sales_rank', 'sales_diff_1', 'price_to_route_month_mean', 'route_month_mean_price', 'isReturn', 'isOneway', 'isNormCabin', 'is_weekend_dept', 'is_weekend_purchase', 'is_sg_holiday_dept', 'is_us_holiday_dept', 'is_cn_holiday_dept', 'is_fr_holiday_dept', 'is_in_holiday_dept', 'is_ru_holiday_dept', 'is_sg_holiday_purchase', 'is_us_holiday_purchase', 'is_cn_holiday_purchase', 'is_fr_holiday_purchase', 'is_in_holiday_purchase', 'is_ru_holiday_purchase', 'return_x_norm', 'oneway_x_norm', 'return_x_weekend', 'oneway_x_weekend', 'dept_weekday', 'purchase_weekday', 'dept_season', 'Train_Number_All', 'Customer_Cat']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Target: predict SALES (daily tickets sold)\n",
    "TARGET = \"Culmulative_sales\"\n",
    "\n",
    "df = df.copy()\n",
    "df[\"y_log\"] = np.log1p(df[TARGET])\n",
    "\n",
    "# Candidate features (mirrors the price notebook, minus the target to avoid leakage)\n",
    "num_feats = [\n",
    "    \"lead_time_days\",\n",
    "    \"route_sales_rank\", \"sales_diff_1\",  # keep if you allow using lags/prev-day signals\n",
    "    \"price_to_route_month_mean\", \"route_month_mean_price\",\n",
    "    \"stringency_at_purchase\",\n",
    "]\n",
    "\n",
    "bool_feats = [\n",
    "    \"isReturn\",\"isOneway\",\"isNormCabin\",\n",
    "    \"is_weekend_dept\",\"is_weekend_purchase\",\n",
    "    \"is_sg_holiday_dept\",\"is_us_holiday_dept\",\"is_cn_holiday_dept\",\n",
    "    \"is_fr_holiday_dept\",\"is_in_holiday_dept\",\"is_ru_holiday_dept\",\n",
    "    \"is_sg_holiday_purchase\",\"is_us_holiday_purchase\",\"is_cn_holiday_purchase\",\n",
    "    \"is_fr_holiday_purchase\",\"is_in_holiday_purchase\",\"is_ru_holiday_purchase\",\n",
    "    \"return_x_norm\",\"oneway_x_norm\",\"return_x_weekend\",\"oneway_x_weekend\",\n",
    "]\n",
    "\n",
    "cat_feats = [\n",
    "    \"dept_weekday\",\"purchase_weekday\",\"dept_season\",\n",
    "    \"Train_Number_All\",\"Customer_Cat\"\n",
    "]\n",
    "\n",
    "# Keep only columns that exist, and be sure not to include the target as a feature\n",
    "num_feats = [c for c in num_feats if c in df.columns and c != TARGET]\n",
    "bool_feats = [c for c in bool_feats if c in df.columns and c != TARGET]\n",
    "cat_feats = [c for c in cat_feats if c in df.columns and c != TARGET]\n",
    "\n",
    "X_cols = num_feats + bool_feats + cat_feats\n",
    "print(\"Using features:\", X_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c002b6",
   "metadata": {},
   "source": [
    "Time-aware train/test split\n",
    "\n",
    "Don’t shuffle randomly when there’s time involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b267ee28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-01 00:00:00 → 2019-04-22 00:00:00 | TRAIN\n",
      "2019-04-22 00:00:00 → 2019-06-30 00:00:00 | TEST\n"
     ]
    }
   ],
   "source": [
    "# Ensure dates are datetime\n",
    "for c in [\"Purchase_Date\",\"Dept_Date\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "\n",
    "df_sorted = df.sort_values(\"Purchase_Date\").reset_index(drop=True)\n",
    "\n",
    "cut = int(len(df_sorted) * 0.8)  # 80% train, 20% test (time ordered)\n",
    "train = df_sorted.iloc[:cut].copy()\n",
    "test  = df_sorted.iloc[cut:].copy()\n",
    "\n",
    "X_train, y_train = train[X_cols], train[\"y_log\"]\n",
    "X_test,  y_test  = test[X_cols],  test[\"y_log\"]\n",
    "\n",
    "print(train[\"Purchase_Date\"].min(), \"→\", train[\"Purchase_Date\"].max(), \"| TRAIN\")\n",
    "print(test[\"Purchase_Date\"].min(),  \"→\", test[\"Purchase_Date\"].max(),  \"| TEST\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94138be",
   "metadata": {},
   "source": [
    "Preprocess + LASSO (with CV)\n",
    "\n",
    "Scale numeric/boolean, one-hot categoricals, and run LassoCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1aa5ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha (LASSO): 0.0002616504698748821\n",
      "Non-zero coefs: 45\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "numeric = num_feats + bool_feats  # scale numeric + 0/1 flags\n",
    "categorical = cat_feats\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(with_mean=True, with_std=True), numeric),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "alphas = np.logspace(-4, 1.5, 80)  # search ~1e-4 to ~31\n",
    "lasso = LassoCV(alphas=alphas, cv=5, random_state=42, n_jobs=-1, max_iter=20000)\n",
    "\n",
    "pipe_lasso = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"model\", lasso)\n",
    "])\n",
    "\n",
    "pipe_lasso.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best alpha (LASSO):\", pipe_lasso.named_steps[\"model\"].alpha_)\n",
    "print(\"Non-zero coefs:\", np.sum(pipe_lasso.named_steps[\"model\"].coef_ != 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86173f9",
   "metadata": {},
   "source": [
    "Evaluate (log space + back-transform)\n",
    "\n",
    "Report MAE/RMSE/ MAP E on the original price scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7d3f991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO {'R2_tr_log': 0.9485811049455068, 'R2_te_log': 0.950243796623579, 'MAE_tr': 3.4820485810483692, 'RMSE_tr': 8.193981879706076, 'MAPE_tr_%': 22.725564522526312, 'R2_tr_orig': 0.8150330695833223, 'MAE_te': 4.1205054314519485, 'RMSE_te': 8.904420353163447, 'MAPE_te_%': 26.07015161909582, 'R2_te_orig': 0.8407186184199342, 'MAE_te_smear': 4.429821224289429, 'RMSE_te_smear': 9.624903937190064, 'MAPE_te_smear_%': 28.461833913844753, 'R2_te_orig_smear': 0.8138999396188308, 'SmearingFactor': 1.0344097171562976}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate(pipe, X_tr, y_tr, X_te, y_te, label=\"Model\"):\n",
    "    # predictions in log1p space\n",
    "    pred_tr = pipe.predict(X_tr)\n",
    "    pred_te = pipe.predict(X_te)\n",
    "\n",
    "    # true values (original scale)\n",
    "    y_tr_true = np.expm1(y_tr)\n",
    "    y_te_true = np.expm1(y_te)\n",
    "\n",
    "    # naive back-transform\n",
    "    y_tr_hat_naive = np.expm1(pred_tr)\n",
    "    y_te_hat_naive = np.expm1(pred_te)\n",
    "\n",
    "    # Duan smearing correction for log1p models\n",
    "    resid_tr = y_tr - pred_tr                       # residuals in log space\n",
    "    smear = float(np.mean(np.exp(resid_tr)))        # E[exp(e)]\n",
    "    y_tr_hat_smear = smear * np.exp(pred_tr) - 1.0\n",
    "    y_te_hat_smear = smear * np.exp(pred_te) - 1.0\n",
    "\n",
    "    # clip tiny negatives\n",
    "    y_tr_hat_naive = np.clip(y_tr_hat_naive, 0, None)\n",
    "    y_te_hat_naive = np.clip(y_te_hat_naive, 0, None)\n",
    "    y_tr_hat_smear = np.clip(y_tr_hat_smear, 0, None)\n",
    "    y_te_hat_smear = np.clip(y_te_hat_smear, 0, None)\n",
    "\n",
    "    def rmse(y_true, y_pred):\n",
    "        return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "    def mape(y_true, y_pred):\n",
    "        return float(np.mean(np.abs((y_true - y_pred) / np.clip(y_true, 1e-8, None))) * 100)\n",
    "\n",
    "    metrics = {\n",
    "        # log-space fit (your original intent)\n",
    "        \"R2_tr_log\": r2_score(y_tr, pred_tr),\n",
    "        \"R2_te_log\": r2_score(y_te, pred_te),\n",
    "\n",
    "        # original-scale (naive back-transform)\n",
    "        \"MAE_tr\": mean_absolute_error(y_tr_true, y_tr_hat_naive),\n",
    "        \"RMSE_tr\": rmse(y_tr_true, y_tr_hat_naive),\n",
    "        \"MAPE_tr_%\": mape(y_tr_true, y_tr_hat_naive),\n",
    "        \"R2_tr_orig\": r2_score(y_tr_true, y_tr_hat_naive),\n",
    "\n",
    "        \"MAE_te\": mean_absolute_error(y_te_true, y_te_hat_naive),\n",
    "        \"RMSE_te\": rmse(y_te_true, y_te_hat_naive),\n",
    "        \"MAPE_te_%\": mape(y_te_true, y_te_hat_naive),\n",
    "        \"R2_te_orig\": r2_score(y_te_true, y_te_hat_naive),\n",
    "\n",
    "        # smearing-corrected (often better calibrated)\n",
    "        \"MAE_te_smear\": mean_absolute_error(y_te_true, y_te_hat_smear),\n",
    "        \"RMSE_te_smear\": rmse(y_te_true, y_te_hat_smear),\n",
    "        \"MAPE_te_smear_%\": mape(y_te_true, y_te_hat_smear),\n",
    "        \"R2_te_orig_smear\": r2_score(y_te_true, y_te_hat_smear),\n",
    "\n",
    "        \"SmearingFactor\": smear,\n",
    "    }\n",
    "\n",
    "    print(label, metrics)\n",
    "    return metrics\n",
    "\n",
    "# usage\n",
    "m_lasso = evaluate(pipe_lasso, X_train, y_train, X_test, y_test, \"LASSO\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22611717",
   "metadata": {},
   "source": [
    "Which features did LASSO keep?\n",
    "\n",
    "Get feature names after preprocessing and list non-zero coefficients (standardized)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e2d2bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO kept 45 / 61 features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>route_sales_rank</td>\n",
       "      <td>1.096806e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Train_Number_All_K</td>\n",
       "      <td>2.316592e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Train_Number_All_M</td>\n",
       "      <td>2.264746e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Train_Number_All_D</td>\n",
       "      <td>1.126999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Train_Number_All_J</td>\n",
       "      <td>1.019788e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Train_Number_All_A</td>\n",
       "      <td>9.676861e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Train_Number_All_L</td>\n",
       "      <td>9.564199e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Train_Number_All_N</td>\n",
       "      <td>4.702394e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>dept_season_Winter</td>\n",
       "      <td>1.827122e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dept_weekday_Friday</td>\n",
       "      <td>1.678413e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sales_diff_1</td>\n",
       "      <td>1.586245e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dept_weekday_Thursday</td>\n",
       "      <td>1.441301e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>oneway_x_norm</td>\n",
       "      <td>1.435456e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>isNormCabin</td>\n",
       "      <td>1.340616e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>route_month_mean_price</td>\n",
       "      <td>4.148679e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>is_weekend_purchase</td>\n",
       "      <td>3.627140e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>return_x_weekend</td>\n",
       "      <td>3.517000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>is_in_holiday_dept</td>\n",
       "      <td>1.645178e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>is_sg_holiday_dept</td>\n",
       "      <td>1.056653e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>is_cn_holiday_purchase</td>\n",
       "      <td>9.383234e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>isReturn</td>\n",
       "      <td>8.089546e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>oneway_x_weekend</td>\n",
       "      <td>2.484317e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>dept_season_Autumn</td>\n",
       "      <td>1.935409e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>is_in_holiday_purchase</td>\n",
       "      <td>1.278495e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Customer_Cat_B</td>\n",
       "      <td>1.080203e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>is_cn_holiday_dept</td>\n",
       "      <td>-8.717988e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>is_fr_holiday_dept</td>\n",
       "      <td>-1.108142e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>is_ru_holiday_purchase</td>\n",
       "      <td>-1.401781e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>is_us_holiday_dept</td>\n",
       "      <td>-1.974664e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>is_ru_holiday_dept</td>\n",
       "      <td>-4.111012e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature      coef_std\n",
       "1         route_sales_rank  1.096806e+00\n",
       "39      Train_Number_All_K  2.316592e-01\n",
       "41      Train_Number_All_M  2.264746e-01\n",
       "33      Train_Number_All_D  1.126999e-01\n",
       "38      Train_Number_All_J  1.019788e-01\n",
       "30      Train_Number_All_A  9.676861e-02\n",
       "40      Train_Number_All_L  9.564199e-02\n",
       "42      Train_Number_All_N  4.702394e-02\n",
       "29      dept_season_Winter  1.827122e-02\n",
       "23     dept_weekday_Friday  1.678413e-02\n",
       "2             sales_diff_1  1.586245e-02\n",
       "24   dept_weekday_Thursday  1.441301e-02\n",
       "20           oneway_x_norm  1.435456e-02\n",
       "7              isNormCabin  1.340616e-02\n",
       "4   route_month_mean_price  4.148679e-03\n",
       "9      is_weekend_purchase  3.627140e-03\n",
       "21        return_x_weekend  3.517000e-03\n",
       "14      is_in_holiday_dept  1.645178e-03\n",
       "10      is_sg_holiday_dept  1.056653e-03\n",
       "16  is_cn_holiday_purchase  9.383234e-04\n",
       "5                 isReturn  8.089546e-04\n",
       "22        oneway_x_weekend  2.484317e-04\n",
       "26      dept_season_Autumn  1.935409e-04\n",
       "17  is_in_holiday_purchase  1.278495e-04\n",
       "44          Customer_Cat_B  1.080203e-16\n",
       "12      is_cn_holiday_dept -8.717988e-04\n",
       "13      is_fr_holiday_dept -1.108142e-03\n",
       "18  is_ru_holiday_purchase -1.401781e-03\n",
       "11      is_us_holiday_dept -1.974664e-03\n",
       "15      is_ru_holiday_dept -4.111012e-03"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "ohe = pipe_lasso.named_steps[\"pre\"].named_transformers_[\"cat\"]\n",
    "cat_names = []\n",
    "if hasattr(ohe, \"get_feature_names_out\"):\n",
    "    cat_names = list(ohe.get_feature_names_out(cat_feats))\n",
    "else:\n",
    "    # Fallback in older sklearn\n",
    "    cat_names = []\n",
    "num_names = numeric\n",
    "\n",
    "feat_names = num_names + cat_names\n",
    "\n",
    "coefs = pipe_lasso.named_steps[\"model\"].coef_\n",
    "keep_mask = coefs != 0\n",
    "kept = [(feat_names[i], coefs[i]) for i in range(len(coefs)) if keep_mask[i]]\n",
    "\n",
    "# Standardize coefficients (already standardized for numeric/booleans; OHE are as-is)\n",
    "df_kept = pd.DataFrame(kept, columns=[\"feature\",\"coef_std\"]).sort_values(\"coef_std\", ascending=False)\n",
    "\n",
    "print(f\"LASSO kept {len(df_kept)} / {len(feat_names)} features\")\n",
    "df_kept.head(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dc0b5f",
   "metadata": {},
   "source": [
    "Human-readable formula\n",
    "\n",
    "Coefficients above are for standardized inputs. To get a simple linear formula in original units, refit a plain LinearRegression on only the selected columns using the same one-hot, but without scaling numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbabb120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model (log-sales) with selected features\n",
      "Intercept: 0.7994945005441145\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Train_Number_All_B</td>\n",
       "      <td>-0.371907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Train_Number_All_E</td>\n",
       "      <td>-0.340393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Train_Number_All_G</td>\n",
       "      <td>-0.248665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Train_Number_All_K</td>\n",
       "      <td>0.243955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Train_Number_All_M</td>\n",
       "      <td>0.237011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Train_Number_All_D</td>\n",
       "      <td>0.119258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Train_Number_All_L</td>\n",
       "      <td>0.115413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Train_Number_All_J</td>\n",
       "      <td>0.110919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Train_Number_All_A</td>\n",
       "      <td>0.106757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Train_Number_All_N</td>\n",
       "      <td>0.076910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>isOneway</td>\n",
       "      <td>-0.069425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>oneway_x_norm</td>\n",
       "      <td>0.061996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Train_Number_All_F</td>\n",
       "      <td>-0.056755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Train_Number_All_I</td>\n",
       "      <td>-0.053000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>price_to_route_month_mean</td>\n",
       "      <td>-0.039008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Train_Number_All_C</td>\n",
       "      <td>-0.031903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>isNormCabin</td>\n",
       "      <td>0.029632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>dept_season_Spring</td>\n",
       "      <td>-0.027899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>dept_season_Winter</td>\n",
       "      <td>0.025988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>return_x_norm</td>\n",
       "      <td>-0.025812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>is_ru_holiday_dept</td>\n",
       "      <td>-0.019864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dept_weekday_Friday</td>\n",
       "      <td>0.018681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dept_weekday_Thursday</td>\n",
       "      <td>0.016420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Customer_Cat_A</td>\n",
       "      <td>-0.015509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Customer_Cat_B</td>\n",
       "      <td>0.015509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>is_us_holiday_dept</td>\n",
       "      <td>-0.013790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>return_x_weekend</td>\n",
       "      <td>0.012657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>is_weekend_dept</td>\n",
       "      <td>-0.011205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>is_weekend_purchase</td>\n",
       "      <td>0.009669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>is_in_holiday_dept</td>\n",
       "      <td>0.009090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature      coef\n",
       "31         Train_Number_All_B -0.371907\n",
       "34         Train_Number_All_E -0.340393\n",
       "36         Train_Number_All_G -0.248665\n",
       "39         Train_Number_All_K  0.243955\n",
       "41         Train_Number_All_M  0.237011\n",
       "33         Train_Number_All_D  0.119258\n",
       "40         Train_Number_All_L  0.115413\n",
       "38         Train_Number_All_J  0.110919\n",
       "30         Train_Number_All_A  0.106757\n",
       "42         Train_Number_All_N  0.076910\n",
       "6                    isOneway -0.069425\n",
       "20              oneway_x_norm  0.061996\n",
       "35         Train_Number_All_F -0.056755\n",
       "37         Train_Number_All_I -0.053000\n",
       "3   price_to_route_month_mean -0.039008\n",
       "32         Train_Number_All_C -0.031903\n",
       "7                 isNormCabin  0.029632\n",
       "27         dept_season_Spring -0.027899\n",
       "29         dept_season_Winter  0.025988\n",
       "19              return_x_norm -0.025812\n",
       "15         is_ru_holiday_dept -0.019864\n",
       "23        dept_weekday_Friday  0.018681\n",
       "24      dept_weekday_Thursday  0.016420\n",
       "43             Customer_Cat_A -0.015509\n",
       "44             Customer_Cat_B  0.015509\n",
       "11         is_us_holiday_dept -0.013790\n",
       "21           return_x_weekend  0.012657\n",
       "8             is_weekend_dept -0.011205\n",
       "9         is_weekend_purchase  0.009669\n",
       "14         is_in_holiday_dept  0.009090"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit a plain LinearRegression on ONLY the LASSO-selected columns\n",
    "# using one-hot encoding for categoricals (no numeric scaling).\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Names from the LASSO pipeline\n",
    "ohe = pipe_lasso.named_steps[\"pre\"].named_transformers_.get(\"cat\", None)\n",
    "cat_names = (\n",
    "    ohe.get_feature_names_out(categorical)\n",
    "    if (ohe is not None and hasattr(ohe, \"get_feature_names_out\") and categorical)\n",
    "    else np.array([])\n",
    ")\n",
    "feat_names = np.array(list(numeric) + list(cat_names))\n",
    "\n",
    "# Mask of columns LASSO kept\n",
    "coefs = pipe_lasso.named_steps[\"model\"].coef_\n",
    "mask = coefs != 0\n",
    "selected_names = feat_names[mask]\n",
    "\n",
    "# Build a \"readable\" preprocessor: passthrough numeric, OHE categoricals\n",
    "pre_readable = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", \"passthrough\", numeric),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "# Fit/transform train features\n",
    "Xtr2 = pre_readable.fit_transform(X_train)\n",
    "\n",
    "# Align transformed column names with this encoder\n",
    "ohe2 = pre_readable.named_transformers_.get(\"cat\", None)\n",
    "cat_names2 = (\n",
    "    ohe2.get_feature_names_out(categorical)\n",
    "    if (ohe2 is not None and hasattr(ohe2, \"get_feature_names_out\") and categorical)\n",
    "    else np.array([])\n",
    ")\n",
    "feat_names2 = np.array(list(numeric) + list(cat_names2))\n",
    "\n",
    "# Keep only LASSO-selected columns\n",
    "selector = np.isin(feat_names2, selected_names)\n",
    "Xtr2_sel = Xtr2[:, selector]\n",
    "feat_names_sel = feat_names2[selector]\n",
    "\n",
    "# Refit linear model on log-sales (y_train already = log1p(SALES))\n",
    "lin = LinearRegression()\n",
    "lin.fit(Xtr2_sel, y_train)\n",
    "\n",
    "print(\"Linear model (log-sales) with selected features\")\n",
    "print(\"Intercept:\", lin.intercept_)\n",
    "pd.DataFrame(\n",
    "    {\"feature\": feat_names_sel, \"coef\": lin.coef_}\n",
    ").sort_values(\"coef\", key=lambda s: np.abs(s), ascending=False).head(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252cc0a0",
   "metadata": {},
   "source": [
    "Your formula in log space is:\n",
    "log(1 + price) = Intercept + Σ coef_i * feature_i\n",
    "To predict price: price_hat = exp(Intercept + Σ coef_i * feature_i) - 1.\n",
    "\n",
    "(If you want statistical p-values / confidence intervals, swap LinearRegression with statsmodels.api.OLS on Xtr_sel and y_train.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e417ec",
   "metadata": {},
   "source": [
    "Which ones to keep? (beyond LASSO)\n",
    "\n",
    "Permutation importance (model-agnostic): keeps features that truly affect predictions on the holdout.\n",
    "\n",
    "Stability selection (bootstrap): keeps features repeatedly chosen across resamples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ab577f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
