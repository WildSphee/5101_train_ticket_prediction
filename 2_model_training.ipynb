{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a725f97",
   "metadata": {},
   "source": [
    "1) Define the objective + guard against leakage\n",
    "\n",
    "Decide what you can know at prediction time. If you’re quoting a price at purchase time, drop any features that peek into the future (e.g., COVID around departure if not known yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a75453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Target (log helps linear models + stabilizes variance)\n",
    "TARGET = \"mean_net_ticket_price\"\n",
    "df = df.copy()\n",
    "df[\"y_log\"] = np.log1p(df[TARGET])\n",
    "\n",
    "# Candidate features you likely have (add/remove as needed)\n",
    "num_feats = [\n",
    "    \"lead_time_days\",\n",
    "    \"Culmulative_sales\",\"route_sales_rank\",\"sales_diff_1\",\n",
    "    \"price_to_route_month_mean\",\"route_month_mean_price\",\n",
    "    # covid @ purchase ONLY if allowed at quote time:\n",
    "    \"covid_cases_at_purchase\",\"stringency_at_purchase\",\n",
    "    # OPTIONAL (if you allow future info at train time; otherwise comment out):\n",
    "    # \"covid_cases_at_departure\",\"covid_7d_sum_before_departure\",\"covid_14d_sum_before_departure\",\"covid_30d_sum_before_departure\",\n",
    "]\n",
    "\n",
    "bool_feats = [\n",
    "    \"isReturn\",\"isOneway\",\"isNormCabin\",\n",
    "    \"is_weekend_dept\",\"is_weekend_purchase\",\n",
    "    \"is_holiday_dept\",\"is_holiday_purchase\",   # SG earlier\n",
    "    \"is_sg_holiday_dept\",\"is_us_holiday_dept\",\"is_cn_holiday_dept\",\"is_fr_holiday_dept\",\"is_in_holiday_dept\",\"is_ru_holiday_dept\",\n",
    "    \"is_sg_holiday_purchase\",\"is_us_holiday_purchase\",\"is_cn_holiday_purchase\",\"is_fr_holiday_purchase\",\"is_in_holiday_purchase\",\"is_ru_holiday_purchase\",\n",
    "    \"return_x_norm\",\"oneway_x_norm\",\"return_x_weekend\",\"oneway_x_weekend\",\n",
    "]\n",
    "\n",
    "cat_feats = [\n",
    "    \"dept_weekday\",\"purchase_weekday\",\"dept_season\",\n",
    "    \"Train_Number_All\",\"Customer_Cat\"\n",
    "]\n",
    "\n",
    "# Keep only columns that exist\n",
    "num_feats  = [c for c in num_feats  if c in df.columns]\n",
    "bool_feats = [c for c in bool_feats if c in df.columns]\n",
    "cat_feats  = [c for c in cat_feats  if c in df.columns]\n",
    "\n",
    "X_cols = num_feats + bool_feats + cat_feats\n",
    "print(\"Using features:\", X_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c002b6",
   "metadata": {},
   "source": [
    "Time-aware train/test split\n",
    "\n",
    "Don’t shuffle randomly when there’s time involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b267ee28",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Ensure dates are datetime\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mPurchase_Date\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mDept_Date\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m.columns:\n\u001b[32m      4\u001b[39m         df[c] = pd.to_datetime(df[c], errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m df_sorted = df.sort_values(\u001b[33m\"\u001b[39m\u001b[33mPurchase_Date\u001b[39m\u001b[33m\"\u001b[39m).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Ensure dates are datetime\n",
    "for c in [\"Purchase_Date\",\"Dept_Date\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "\n",
    "df_sorted = df.sort_values(\"Purchase_Date\").reset_index(drop=True)\n",
    "\n",
    "cut = int(len(df_sorted) * 0.8)  # 80% train, 20% test (time ordered)\n",
    "train = df_sorted.iloc[:cut].copy()\n",
    "test  = df_sorted.iloc[cut:].copy()\n",
    "\n",
    "X_train, y_train = train[X_cols], train[\"y_log\"]\n",
    "X_test,  y_test  = test[X_cols],  test[\"y_log\"]\n",
    "\n",
    "print(train[\"Purchase_Date\"].min(), \"→\", train[\"Purchase_Date\"].max(), \"| TRAIN\")\n",
    "print(test[\"Purchase_Date\"].min(),  \"→\", test[\"Purchase_Date\"].max(),  \"| TEST\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94138be",
   "metadata": {},
   "source": [
    "Preprocess + LASSO (with CV)\n",
    "\n",
    "Scale numeric/boolean, one-hot categoricals, and run LassoCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1aa5ae6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompose\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder, StandardScaler\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LassoCV, ElasticNetCV, LinearRegression\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "numeric = num_feats + bool_feats   # scale both numeric + 0/1 flags\n",
    "categorical = cat_feats\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(with_mean=True, with_std=True), numeric),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False), categorical),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "alphas = np.logspace(-4, 1.5, 80)  # search from 1e-4 to ~31\n",
    "lasso = LassoCV(alphas=alphas, cv=5, random_state=42, n_jobs=-1, max_iter=20000)\n",
    "\n",
    "pipe_lasso = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"model\", lasso)\n",
    "])\n",
    "\n",
    "pipe_lasso.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best alpha (LASSO):\", pipe_lasso.named_steps[\"model\"].alpha_)\n",
    "print(\"Non-zero coefs:\", np.sum(pipe_lasso.named_steps[\"model\"].coef_ != 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86173f9",
   "metadata": {},
   "source": [
    "Evaluate (log space + back-transform)\n",
    "\n",
    "Report MAE/RMSE/ MAP E on the original price scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7d3f991",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error, mean_squared_error, r2_score\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate\u001b[39m(pipe, X_tr, y_tr, X_te, y_te, label=\u001b[33m\"\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate(pipe, X_tr, y_tr, X_te, y_te, label=\"Model\"):\n",
    "    pred_tr = pipe.predict(X_tr)\n",
    "    pred_te = pipe.predict(X_te)\n",
    "\n",
    "    # back-transform\n",
    "    y_tr_hat = np.expm1(pred_tr)\n",
    "    y_te_hat = np.expm1(pred_te)\n",
    "    y_tr_true = np.expm1(y_tr)\n",
    "    y_te_true = np.expm1(y_te)\n",
    "\n",
    "    def mape(y_true, y_pred):\n",
    "        return np.mean(np.abs((y_true - y_pred) / np.clip(y_true, 1e-8, None))) * 100\n",
    "\n",
    "    metrics = {\n",
    "        \"MAE_tr\": mean_absolute_error(y_tr_true, y_tr_hat),\n",
    "        \"RMSE_tr\": mean_squared_error(y_tr_true, y_tr_hat, squared=False),\n",
    "        \"MAPE_tr_%\": mape(y_tr_true, y_tr_hat),\n",
    "        \"R2_tr\": r2_score(y_tr, pred_tr),  # R^2 in log space\n",
    "\n",
    "        \"MAE_te\": mean_absolute_error(y_te_true, y_te_hat),\n",
    "        \"RMSE_te\": mean_squared_error(y_te_true, y_te_hat, squared=False),\n",
    "        \"MAPE_te_%\": mape(y_te_true, y_te_hat),\n",
    "        \"R2_te\": r2_score(y_te, pred_te),\n",
    "    }\n",
    "    print(label, metrics)\n",
    "    return metrics\n",
    "\n",
    "m_lasso = evaluate(pipe_lasso, X_train, y_train, X_test, y_test, \"LASSO\")\n",
    "# Optional:\n",
    "# m_enet  = evaluate(pipe_enet,  X_train, y_train, X_test, y_test, \"ElasticNet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22611717",
   "metadata": {},
   "source": [
    "Which features did LASSO keep?\n",
    "\n",
    "Get feature names after preprocessing and list non-zero coefficients (standardized)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e2d2bd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'categorical' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Get transformed feature names\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m cat_names = pipe_lasso.named_steps[\u001b[33m\"\u001b[39m\u001b[33mpre\u001b[39m\u001b[33m\"\u001b[39m].named_transformers_[\u001b[33m\"\u001b[39m\u001b[33mcat\u001b[39m\u001b[33m\"\u001b[39m].get_feature_names_out(categorical) \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcategorical\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m np.array([])\n\u001b[32m      3\u001b[39m feat_names = np.concatenate([numeric, cat_names])\n\u001b[32m      5\u001b[39m coefs = pipe_lasso.named_steps[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m].coef_\n",
      "\u001b[31mNameError\u001b[39m: name 'categorical' is not defined"
     ]
    }
   ],
   "source": [
    "# Get transformed feature names\n",
    "cat_names = pipe_lasso.named_steps[\"pre\"].named_transformers_[\"cat\"].get_feature_names_out(categorical) if categorical else np.array([])\n",
    "feat_names = np.concatenate([numeric, cat_names])\n",
    "\n",
    "coefs = pipe_lasso.named_steps[\"model\"].coef_\n",
    "mask = coefs != 0\n",
    "selected = pd.DataFrame({\n",
    "    \"feature\": feat_names[mask],\n",
    "    \"coef_std\": coefs[mask]\n",
    "}).sort_values(\"coef_std\", key=lambda s: np.abs(s), ascending=False)\n",
    "\n",
    "print(f\"LASSO kept {mask.sum()} / {len(feat_names)} features\")\n",
    "selected.head(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dc0b5f",
   "metadata": {},
   "source": [
    "Human-readable formula\n",
    "\n",
    "Coefficients above are for standardized inputs. To get a simple linear formula in original units, refit a plain LinearRegression on only the selected columns using the same one-hot, but without scaling numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbabb120",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ColumnTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Build a 'no-scale' preprocessor (one-hot only), then restrict to selected columns\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m pre_noscale = \u001b[43mColumnTransformer\u001b[49m(\n\u001b[32m      3\u001b[39m     transformers=[\n\u001b[32m      4\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33mnum\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m, numeric + bool_feats),\n\u001b[32m      5\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33mcat\u001b[39m\u001b[33m\"\u001b[39m, OneHotEncoder(handle_unknown=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m, sparse=\u001b[38;5;28;01mFalse\u001b[39;00m), categorical),\n\u001b[32m      6\u001b[39m     ],\n\u001b[32m      7\u001b[39m     remainder=\u001b[33m\"\u001b[39m\u001b[33mdrop\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m )\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Fit on TRAIN to get transformed matrix & names\u001b[39;00m\n\u001b[32m     11\u001b[39m Xtr_n = pre_noscale.fit_transform(X_train)\n",
      "\u001b[31mNameError\u001b[39m: name 'ColumnTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "# Build a 'no-scale' preprocessor (one-hot only), then restrict to selected columns\n",
    "pre_noscale = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", \"passthrough\", numeric + bool_feats),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False), categorical),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# Fit on TRAIN to get transformed matrix & names\n",
    "Xtr_n = pre_noscale.fit_transform(X_train)\n",
    "cat_names_n = pre_noscale.named_transformers_[\"cat\"].get_feature_names_out(categorical) if categorical else np.array([])\n",
    "feat_names_n = np.concatenate([numeric + bool_feats, cat_names_n])\n",
    "\n",
    "# Keep only the features LASSO selected (intersection by name)\n",
    "keep_set = set(selected[\"feature\"])\n",
    "keep_idx = [i for i, n in enumerate(feat_names_n) if n in keep_set]\n",
    "\n",
    "Xtr_sel = Xtr_n[:, keep_idx]\n",
    "Xte_sel = pre_noscale.transform(X_test)[:, keep_idx]\n",
    "feat_sel_names = [feat_names_n[i] for i in keep_idx]\n",
    "\n",
    "ols = LinearRegression()\n",
    "ols.fit(Xtr_sel, y_train)\n",
    "\n",
    "coef = pd.DataFrame({\"feature\": feat_sel_names, \"coef\": ols.coef_}).sort_values(\"coef\", key=lambda s: np.abs(s), ascending=False)\n",
    "intercept = ols.intercept_\n",
    "\n",
    "print(\"Linear model (log-price) with selected features\")\n",
    "print(\"Intercept:\", intercept)\n",
    "coef.head(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252cc0a0",
   "metadata": {},
   "source": [
    "Your formula in log space is:\n",
    "log(1 + price) = Intercept + Σ coef_i * feature_i\n",
    "To predict price: price_hat = exp(Intercept + Σ coef_i * feature_i) - 1.\n",
    "\n",
    "(If you want statistical p-values / confidence intervals, swap LinearRegression with statsmodels.api.OLS on Xtr_sel and y_train.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e417ec",
   "metadata": {},
   "source": [
    "Which ones to keep? (beyond LASSO)\n",
    "\n",
    "Permutation importance (model-agnostic): keeps features that truly affect predictions on the holdout.\n",
    "\n",
    "Stability selection (bootstrap): keeps features repeatedly chosen across resamples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ab3adca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minspection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m permutation_importance\n\u001b[32m      3\u001b[39m perm = permutation_importance(pipe_lasso, X_test, y_test, n_repeats=\u001b[32m40\u001b[39m, random_state=\u001b[32m42\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m      4\u001b[39m perm_imp = pd.DataFrame({\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfeature\u001b[39m\u001b[33m\"\u001b[39m: feat_names,\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimport_mean\u001b[39m\u001b[33m\"\u001b[39m: perm.importances_mean,\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimport_std\u001b[39m\u001b[33m\"\u001b[39m: perm.importances_std\n\u001b[32m      8\u001b[39m }).sort_values(\u001b[33m\"\u001b[39m\u001b[33mimport_mean\u001b[39m\u001b[33m\"\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "perm = permutation_importance(pipe_lasso, X_test, y_test, n_repeats=40, random_state=42, n_jobs=-1)\n",
    "perm_imp = pd.DataFrame({\n",
    "    \"feature\": feat_names,\n",
    "    \"import_mean\": perm.importances_mean,\n",
    "    \"import_std\": perm.importances_std\n",
    "}).sort_values(\"import_mean\", ascending=False)\n",
    "\n",
    "perm_imp.head(20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
